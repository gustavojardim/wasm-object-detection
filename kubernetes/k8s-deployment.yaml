apiVersion: v1
kind: Pod
metadata:
  name: wasm-inference
  labels:
    app: wasm-inference
  annotations:
    module.wasm.image/variant: "compat"
spec:
  runtimeClassName: wasmtime
  restartPolicy: Always
  containers:
    - name: inference
      image: 192.168.0.108:32000/wasm-inference:latest
      imagePullPolicy: Always
      # resources:
      #   requests:
      #     memory: "1.5Gi"
      #     cpu: "500m"
      #   limits:
      #     # Allows the pod to burst to 4 cores during inference
      #     memory: "2Gi"
      #     cpu: "4000m"
      command: ["app.wasm", "--udp", "--debug", "--profile"]
      ports:
        - containerPort: 8080
          name: tcp
          protocol: TCP
        - containerPort: 8081
          name: udp
          protocol: UDP
---
apiVersion: v1
kind: Service
metadata:
  name: wasm-inference
spec:
  type: NodePort
  selector:
    app: wasm-inference
  ports:
    - name: tcp
      port: 8080
      targetPort: 8080
      nodePort: 30080
      protocol: TCP
    - name: udp
      port: 8081
      targetPort: 8081
      nodePort: 30081
      protocol: UDP